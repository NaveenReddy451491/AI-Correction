{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "the sentence_transformers library is utilized to facilitate the calculation of semantic similarity between two given sentences. This library allows for the conversion of text inputs into numerical embeddings using pre-trained models, enabling the comparison of semantic meanings. The cosine similarity metric is then employed to quantify the degree of similarity between the embeddings, providing a measure of the semantic similarity between the sentences."
      ],
      "metadata": {
        "id": "2pj89P9jx6lD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "id": "B0QklDHXybG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import wordnet as wn\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def calculate_semantic_similarity(main_sentence, text):\n",
        "    model = SentenceTransformer('paraphrase-distilroberta-base-v1')\n",
        "    sentences = [main_sentence, text]\n",
        "    sentence_embeddings = model.encode(sentences)\n",
        "    similarity_score = util.pytorch_cos_sim(sentence_embeddings[0], sentence_embeddings[1]).item()\n",
        "    return similarity_score\n",
        "\n",
        "def calculate_polarity_score(text):\n",
        "    sia = SentimentIntensityAnalyzer()\n",
        "    polarity_score = sia.polarity_scores(text)\n",
        "    return polarity_score['compound']\n",
        "\n",
        "def check_grammatical_similarity(main_sentence, text):\n",
        "    main_words = word_tokenize(main_sentence)\n",
        "    text_words = word_tokenize(text)\n",
        "    similarity_scores = []\n",
        "    for main_word in main_words:\n",
        "        main_synsets = wn.synsets(main_word)\n",
        "        max_similarity = 0\n",
        "        for text_word in text_words:\n",
        "            text_synsets = wn.synsets(text_word)\n",
        "            for main_synset in main_synsets:\n",
        "                for text_synset in text_synsets:\n",
        "                    similarity = main_synset.path_similarity(text_synset)\n",
        "                    if similarity is not None and similarity > max_similarity:\n",
        "                        max_similarity = similarity\n",
        "        similarity_scores.append(max_similarity)\n",
        "    avg_similarity_score = np.mean(similarity_scores)\n",
        "    return avg_similarity_score\n",
        "\n",
        "main_sentence = \" Polymerization is the process to create polymers. These polymers are then processed to make various kinds of plastic products. During polymerization, smaller molecules, called monomers or building blocks, are chemically combined to create larger molecules or a macromolecule  \"\n",
        "text = \" polymerization is the process of creating polymers.The processs of combining munltiple  to create a polymermonomers plastic product is called polymerization.\"\n",
        "\n",
        "main_sentence_polarity = calculate_polarity_score(main_sentence)\n",
        "text_polarity = calculate_polarity_score(text)\n",
        "\n",
        "print(f\"Main Sentence Polarity Score: {main_sentence_polarity:.2f}\")\n",
        "print(f\"Text Polarity Score: {text_polarity:.2f}\")\n",
        "\n",
        "grammatical_similarity = check_grammatical_similarity(main_sentence, text)\n",
        "similarity_score = calculate_semantic_similarity(main_sentence, text)\n",
        "\n",
        "max_marks = float(input(\"Enter the maximum marks: \"))\n",
        "\n",
        "if main_sentence_polarity > 0 and text_polarity > 0:\n",
        "    if grammatical_similarity > 0.3 and similarity_score > 0.4 and text_polarity > 0.2:\n",
        "        marks = similarity_score * max_marks\n",
        "    else:\n",
        "        marks = max_marks//10\n",
        "\n",
        "    print(f\"Marks: {marks:.0f} out of {max_marks:.2f}\")\n",
        "elif main_sentence_polarity <= 0 and text_polarity <= 0:\n",
        "    print(\"Text polarity is negative. It cannot be considered as a correct answer.\")\n",
        "else:\n",
        "    print(f\"Grammatical Similarity Score: {grammatical_similarity:.2f}\")\n",
        "    print(f\"Semantic Similarity Score: {similarity_score:.2f}\")\n",
        "\n",
        "    if grammatical_similarity > 0.3 and similarity_score > 0.4 and text_polarity > 0.2:\n",
        "        marks = similarity_score * max_marks\n",
        "    else:\n",
        "        marks = max_marks//10\n",
        "\n",
        "    print(f\"Marks: {marks:.0f} out of {max_marks:.2f}\")"
      ],
      "metadata": {
        "id": "NV2EThQex1kG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}